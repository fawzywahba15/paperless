# Paperless - Verteiltes Dokumentenmanagementsystem

Ein modernes, Microservice-basiertes System zur Archivierung, Verarbeitung und Suche von Dokumenten. Entwickelt im Rahmen des Semesterprojekts (Sprints 1-7).

Das System erm√∂glicht den Upload von PDFs, extrahiert Text mittels OCR (Tesseract), generiert KI-Zusammenfassungen (Google Gemini), speichert Daten relational (PostgreSQL) sowie als Objekte (MinIO) und erm√∂glicht eine performante Volltextsuche (ElasticSearch). Zus√§tzlich werden externe Zugriffsdaten √ºber einen automatisierten Batch-Prozess importiert.

---

## üöÄ Features & Highlights

Das Projekt deckt alle Anforderungen der Sprints 1 bis 7 ab:

* **üìÑ Dokumenten-Upload:**
    * Upload via Web-UI (Angular) oder REST API.
    * Speicherung der Originaldatei in **MinIO** (S3-kompatibler Object Storage).
    * Speicherung der Metadaten in **PostgreSQL**.
* **üîÑ Automatisierter Batch-Import:**
    * √úberwachung des Dateisystems (scan_input) auf neue XML-Zugriffslogs.
    * Automatischer Import in die Datenbank und Archivierung der verarbeiteten Dateien.
    * Konfigurierbare Pfade und Zeitplanung (Scheduling).
* **‚öôÔ∏è Asynchrone Verarbeitung (Messaging):**
    * Nutzung von **RabbitMQ** zur Entkopplung von Upload und Verarbeitung.
    * Skalierbare Worker-Architektur.
* **üîç OCR & Texterkennung:**
    * Automatisierte Textextraktion mit **Tesseract OCR**.
* **ü§ñ KI-Integration (GenAI):**
    * Automatische Zusammenfassung des Dokumenteninhalts mittels **Google Gemini API**.
* **üîé Intelligente Suche (ElasticSearch):**
    * Indizierung aller Dokumenteninhalte.
    * Fuzzy-Search (unscharfe Suche) √ºber Titel und OCR-Content.
* **üîó Secure Document Sharing (Additional Use-Case):**
    * Erstellen von zeitlich begrenzten Share-Links.
    * Tracking von Zugriffen (Access Logs) in der Datenbank.
* **üìö API Dokumentation:**
    * Vollst√§ndige OpenAPI/Swagger Spezifikation integriert.

---

## üõ†Ô∏è Technologie-Stack

### Backend
* **Framework:** Spring Boot 3 (Java 21)
* **Kommunikation:** REST, AMQP (RabbitMQ)
* **Datenbank:** PostgreSQL 16 (Hibernate/JPA)
* **Search Engine:** ElasticSearch 8
* **Object Storage:** MinIO
* **Tools:** Lombok, MapStruct (Entity-DTO Mapping), Jackson (XML/JSON), Maven

### Frontend
* **Framework:** Angular 18 (Standalone Components)
* **Styling:** Custom CSS, Responsive Layout
* **Server:** Nginx (als Reverse Proxy und Webserver)

### Infrastruktur
* **Containerisierung:** Docker & Docker Compose
* **Orchestrierung:** Alle Services starten mit einem Befehl.

---

## üèÉ‚Äç‚ôÇÔ∏è Installation & Start

### Voraussetzungen
* Docker & Docker Desktop installiert.
* Git installiert.
* (Optional) Java 21 JDK & Maven f√ºr lokale Entwicklung.

### Starten der Anwendung
Das gesamte System wird √ºber Docker Compose gestartet. Es ist keine lokale Installation von Datenbanken oder Java notwendig.

---
1.  **Repository klonen:**
    ```bash
    git clone https://github.com/fawzywahba15/paperless
    cd paperless
    ```
---
2. **API Key Konfiguration**

Aus Sicherheitsgr√ºnden ist der echte API-Key nicht im Repository enthalten. Damit die KI-Funktionen (Document Summarization) funktionieren, ist eine lokale Konfiguration n√∂tig:

1. √ñffnen Sie die Datei `.env.sample` im Hauptverzeichnis.
2. Suchen Sie die Variable `GEMINI_API_KEY`.
3.  Ersetzen Sie den Platzhalter durch Ihren echten Google Gemini API Key:

    ```env
    GEMINI_API_KEY="YourKey"
    ```
---
3. **System bauen und starten:**
    Dieser Befehl baut die Java-JARs, die Angular-App und erstellt die Docker-Images.
    ```bash
    docker-compose up --build
    ```
    *(Der erste Start kann einige Minuten dauern, da Maven-Abh√§ngigkeiten und Docker-Images geladen werden.)*
---
4. **Warten auf Bereitschaft:**
    Warten Sie, bis in den Logs `Started PaperlessRestApplication` und `Started PaperlessServiceApplication` erscheint.

---

## üñ•Ô∏è Nutzung & Zugriff

Nach dem erfolgreichen Start sind folgende Dienste erreichbar:

| Dienst | URL | Beschreibung |
| :--- | :--- | :--- |
| **Web UI** | [http://localhost:8080](http://localhost:8080) | Die Hauptanwendung f√ºr Benutzer. |
| **API Docs** | [http://localhost:8081/swagger-ui/index.html](http://localhost:8081/swagger-ui/index.html) | Swagger UI zum Testen der Endpunkte. |
| **MinIO** | [http://localhost:9090](http://localhost:9090) | S3 Konsole. |
| **RabbitMQ** | [http://localhost:9093](http://localhost:9093) | Messaging Dashboard. |
| **Adminer** | [http://localhost:9091](http://localhost:9091) | Datenbank-Verwaltung. |
### üîë Standard-Zugangsdaten

Damit Sie sich direkt in die Verwaltungsoberfl√§chen einloggen k√∂nnen:

| Dienst | Benutzer / Login | Passwort | Zusatzinfo |
| :--- | :--- | :--- | :--- |
| **Adminer (DB)** | `paperless` | `paperless` | System: **PostgreSQL**, DB: `paperless` |
| **MinIO** | `minioadmin` | `minioadmin` | |
| **RabbitMQ** | `guest` | `guest` | |

---

### Workflow 1: Dokumenten-Upload, KI (Der "Happy Path")

1.  √ñffnen Sie das **Web UI** (`http://localhost:8080`).
2.  Laden Sie ein PDF-Dokument √ºber das Upload-Formular hoch.
3.  **Warten:** Im Hintergrund passiert folgendes:
    * REST-API speichert Datei in MinIO & DB.
    * RabbitMQ Nachricht -> OCR Worker extrahiert Text.
    * GenAI Worker -> Erstellt Zusammenfassung.
    * Indexer -> Speichert Text in ElasticSearch.
4.  Nutzen Sie die **Suchleiste**: Suchen Sie nach einem Wort, das im PDF vorkommt (z.B. "Rechnung", "Wien"). Das Dokument sollte erscheinen.

---

### Workflow 2: Batch-Import testen

Der Batch-Service √ºberwacht Ordner auf XML-Dateien, um externe Access-Logs zu importieren.

1.  Navigieren Sie im Projektordner zu ./scan_input.
2.  Kopieren Sie die bereitgestellte Beispieldatei sample_access_log.xml in diesen Ordner.

Hinweis: Der Scheduler l√§uft zu Demo-Zwecken alle 30 Sekunden (Produktionseinstellung f√ºr 01:00 Uhr ist im Code dokumentiert).
3.  Warten Sie ca. 30 Sekunden.
4.  Ergebnis pr√ºfen:

Die Datei wurde automatisch in den Ordner ./scan_archive verschoben (und umbenannt).

In der Datenbank (Tabelle access_log) sind neue Eintr√§ge sichtbar (via Adminer).

---

### Workflow 3: Document Sharing

1.  Klicken Sie im UI auf den "Share" Button bei einem Dokument.
2.  Ein Link wird generiert. Beim Aufruf wird das Dokument heruntergeladen.
3.  Dieser Zugriff wird in der Datenbank protokolliert.

---

## ‚úÖ Qualit√§tssicherung & Tests

Das Projekt verf√ºgt √ºber eine umfassende Test-Suite, die kritische Pfade und Business-Logik absichert (Code Coverage > 70%).

### 1. Integration Tests (REST API)
F√ºr den Use-Case "Document Upload" wurde ein robuster Integrationstest implementiert:

* **Strategie:** Verwendung von `@WebMvcTest` (Slice Testing).
* **Ablauf:** Der Test pr√ºft den Controller-Layer, das JSON-Mapping und die HTTP-Statuscodes. Externe Abh√§ngigkeiten (DB, MinIO, ElasticSearch) werden gemockt, um Stabilit√§t in der CI/CD-Pipeline (Docker Build) zu garantieren, ohne auf schwere
* **Ausf√ºhrung:** Erfolgt automatisch bei jedem `docker-compose build`.

### 2. Unit Tests

* **Worker Services:** Validierung der Business-Logik f√ºr OCR und GenAI-Verarbeitung.
* **Mapping** Tests f√ºr Entity-DTO Konvertierungen.

```bash
# REST Tests
cd services/paperless-rest
./mvnw test

# Service/Worker Tests
cd services/paperless-services
./mvnw test
```

---

## üß™ Additional Use-Case: Document Sharing

Dieser Use-Case demonstriert die Erweiterung des Datenmodells und der Business-Logik.

* **Funktion:** Benutzer k√∂nnen Dokumente tempor√§r freigeben.
* **Neue Entities:**
    * `ShareLink`: Speichert Token und Ablaufdatum.
    * `AccessLog`: Protokolliert jeden Download-Versuch (Erfolg/Fehler, Zeitstempel).
* **Testen:**
    1.  Klicken Sie im UI auf den blauen "Share" Button bei einem Dokument.
    2.  Ein Link wird generiert (z.B. `http://localhost:8081/api/share/download/xyz123`).
    3.  Beim Aufruf dieses Links wird das Dokument direkt heruntergeladen.
    4.  Pr√ºfung: In der Datenbank-Tabelle `access_log` ist nun ein Eintrag sichtbar.

---

## üìÇ Projektstruktur

```plaintext
paperless/
‚îú‚îÄ‚îÄ compose/                # Configs (DB, Nginx, ElasticSearch)
‚îú‚îÄ‚îÄ scan_input/             # Watch-Folder f√ºr Batch Import
‚îú‚îÄ‚îÄ scan_archive/           # Archiv f√ºr verarbeitete Batch-Dateien
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ paperless-rest/     # Backend API (Spring Boot)
‚îÇ   ‚îú‚îÄ‚îÄ paperless-services/ # Worker Service (OCR, Batch, GenAI)
‚îÇ   ‚îî‚îÄ‚îÄ paperless-web/      # Frontend (Angular)
‚îú‚îÄ‚îÄ docker-compose.yml      # Orchestrierung
‚îú‚îÄ‚îÄ sample_access_log.xml   # Testdatei f√ºr Batch Import
‚îî‚îÄ‚îÄ README.md               # Dokumentation

```

---

## ‚ö†Ô∏è Troubleshooting

1. Upload h√§ngt?
* Pr√ºfen Sie die Logs (docker-compose logs -f paperless-service), ob Tesseract OCR l√§uft.

2. Suche findet nichts?
* Warten Sie einige Sekunden nach dem Upload (ElasticSearch Indexierung ist asynchron).

3. Datenbank-Fehler?
* F√ºhren Sie docker-compose down -v aus, um die Volumes zu l√∂schen und mit einer frischen DB zu starten.

---

## Integrationstests (End-to-End)

Um die vollst√§ndige Funktionskette (Upload -> Queue -> OCR -> AI -> Search) zu testen, wurde ein E2E Test implementiert.

**Voraussetzungen:**
1. Das System muss laufen: `docker-compose up -d --build`
2. Alle Container (REST, Service, DB, Broker, Elastic, MinIO) m√ºssen "healthy" sein.

**Ausf√ºhrung:**
Der Test ist als JUnit Test im `paperless-rest` Modul implementiert.
Befehl:
```bash
# Im root ordner
cd services/paperless-rest
mvn test -Dtest=EndToEndIntegrationTest